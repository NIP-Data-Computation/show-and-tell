{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "piercel_week2_notes2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZA4HiSreTDmb2SB+MsEUw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NIP-Data-Computation/show-and-tell/blob/master/piercel_week2_notes2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNLJtZQFCOeV",
        "colab_type": "text"
      },
      "source": [
        "**Author**: Pierce Lopez <br>\n",
        "**Date Created**: August 11, 2020 <br>\n",
        "**Last Updated**: August 12, 2020 <br> \n",
        "**Description**: Contains my notes on the Data Analyst lesson: _Merging DataFrames with pandas_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QASqRRDJDKHr",
        "colab_type": "text"
      },
      "source": [
        "# Merging DataFrames with pandas\n",
        "For this chapter, we will make use of the `pandas` and `NumPy` functions so do not forget to import the necessary modules!\n",
        "\n",
        "```\n",
        "# import modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "```\n",
        "## Chapter 1: Preparing Data\n",
        "\n",
        "### Section 1: Reading multiple data files\n",
        "\n",
        "1. Tools for pandas data import\n",
        "  * `pd.read_csv()`\n",
        "  * `pd.read_excel()`\n",
        "  * `pd.read_html()`\n",
        "  * `pd.read_json()`\n",
        "\n",
        "2. Load files using loops\n",
        "\n",
        "```\n",
        "# make list of filenames\n",
        "filenames = [\"file1.csv\", \"file2.csv\"]\n",
        "\n",
        "# initialize DataFrame\n",
        "df = []\n",
        "\n",
        "# loop pd.read_csv() over filenames list\n",
        "for f in filenames\n",
        "  df.append(pd.read_csv(f))\n",
        "```\n",
        "\n",
        "3. Load files using list comprehensions\n",
        "\n",
        "```\n",
        "# make list of filenames\n",
        "filenames = [\"file1.csv\", \"file2.csv\"]\n",
        "\n",
        "# read several files using list comprehensions\n",
        "df = [pd.read_csv(f) for f in filenames]\n",
        "```\n",
        "\n",
        "4. Load files using `glob`\n",
        "  * `glob` is a Python module which can be handy for instances where filenames have similar patterns!\n",
        "\n",
        "```\n",
        "# import module\n",
        "import glob\n",
        "\n",
        "# make list of strings that contain the prefix 'sales' and suffix '.csv'\n",
        "filenames = glob('sales*.csv')\n",
        "\n",
        "# read several files using list comprehensions\n",
        "df = [pd.read_csv(f) for f in filenames]\n",
        "```\n",
        "  * The `*` is a wildcard that can match any number of characters.\n",
        "\n",
        "**Additional Insights:**\n",
        "\n",
        "1. You can copy a DataFrame using the `copy()` method.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Section 2: Reindexing DataFrames\n",
        "\n",
        "1. Setting conventions\n",
        "  * Indices - refers to several row labels within one data structure\n",
        "  * Indexes - refers to several row labels from several data structures\n",
        "\n",
        "2. The DataFrame indexes can be accessed using the `.index()` method.\n",
        "3. Manually arrange  indices using `.reindex([list that contains the new order])`\n",
        "  * **Note:** We can reindex using index labels of another DataFrame!\n",
        "4. Arrange indices in order using `.sort_index()`\n",
        "5. Reindexing with missing labels will create new rows with missing values.\n",
        "6. Using the `index_col` argument, we will let a column of our DataFrame be the index of such.\n",
        "\n",
        "**Additional insights:**\n",
        "\n",
        "1. The `.ffill()` method changes `NaN` values to last non-null value.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Section 3: Arithmetic with Series and DataFrames\n",
        "\n",
        "1. `dataframe.divide(col_name, axis = \"rows\")`\n",
        "  * `col_name` acts as a divisor. Each row of the DataFrame will be divided by the corresponding `col_name` value.\n",
        "\n",
        "2. `dataframe.pct_change()`\n",
        "$$ \\%_{change} = {current\\;row\\;value - previous\\;row\\;value\\over previous\\;row\\;value}.$$\n",
        "\n",
        "3. We can add Series values using the `.add()` method.\n",
        "\n",
        "```\n",
        "# arithmetic\n",
        "series1 + series2\n",
        "\n",
        "# .add()\n",
        "series1.add(series2, fill_value = 0)\n",
        "```\n",
        "  * **Note:** Adding Series values where some rows have `NaN` values, the sum will also return `NaN`. To avoid this, we use the `fill_value = 0` argument.\n",
        "  * We can also chain `.add()` to add more Series data!\n",
        "  * **Note:** Adding is index-based!\n",
        "\n",
        "**Additional insights:** \n",
        "1. We can change string characters with the `.str.replace()` method.\n",
        "2. `.resample('A')` allows us to resample a Series.\n",
        "  * 'A' for annual frequency.\n",
        "3. Chaining `.last()` to `.resample()` picks the last element during resampling.\n",
        "4. `.multiply(axis = \"rows\")` is for row-by-row multiplication.\n",
        "5. `parse_dates = True` converts strings into `datetime` objects\n",
        "\n",
        "<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XNy6azPqFXH",
        "colab_type": "text"
      },
      "source": [
        "## Chapter 2: Concatenating Data\n",
        "\n",
        "### Section 1: Appending and concatenating Series\n",
        "\n",
        "1. `series1.append(series2)`\n",
        "  * Stacks rows.\n",
        "  * Works for Series and DataFrames.\n",
        "2. `pd.concat([s1, s2, s3], ignore_index = True)`\n",
        "  * Can stack row-wise or column-wise.\n",
        "  * Works for Series and DataFrames.\n",
        "  * `ignore_index = True` is the argument equivalent of `reset_index(drop = True)`\n",
        "**Note:** When stacking rows, indexes are kept in the stacked version so there wil lbe multiple indices of the same value or label. `reset_index(drop = True)` takes care of that.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Section 2: Appending and concatenating DataFrames\n",
        "\n",
        "1. Appending is similar to Series appending.\n",
        "  * In the case of different indexes and column values, the final DataFrame will keep all indexes (regardless if they are the same) and a number of columns equal to how many unique column names were appended.\n",
        "  * Missing values will be placed on areas where the original individual DataFrames didn't have column values for such.\n",
        "\n",
        "2. Concatenating is also similar to Series concatenation.\n",
        "  * `axis = 0` for row concatenation.\n",
        "  * `axis = 1` for column concatenation.\n",
        "    * **Note:** When stacking row-wise, all indexes will be kept regardless if they are the same. When stacking column-wise, similar indexes will be combined, reducing rows.\n",
        "\n",
        "**Additional insights:** \n",
        "1. `\"%s_top5.csv\" % \"string\"` replaces `%s` with `\"string\"`. \n",
        "2. The `header = 0` argument removes column names from a DataFrame.\n",
        "3. The `names = [list_of_column_names]` argument adds column names to a DataFrame.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Section 3: Concatenation, keys, and multi-indexes\n",
        "\n",
        "1. Multi-level indexing on row concatenations\n",
        "  * `pd.concat([s1, s2], keys = [s1_out_index, s2_out_index], axis = 0)`\n",
        "2. Multi-level indexing on column concatenations\n",
        "  * `pd.concat([s1, s2], keys = [s1_out_index, s2_out_index], axis = 1)`  \n",
        "\n",
        "**Note:** Keys help us distinguish data to avoid confusion!\n",
        "**Additional insights:** \n",
        "1. The `keys` argument are the same with the keys from dictionaries so it will also work if we use `pd.concat()` on dictionaries!\n",
        "\n",
        "```\n",
        "# make dictionary\n",
        "dict = {s1_out_index:s1, s2_out_index:s2}\n",
        "\n",
        "# concatenate\n",
        "`pd.concat(dict, axis = 1)`\n",
        "```\n",
        "2. `pd.IndexSlice` is required when slicing on the inner levels of multilevel indices.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Section 4: Outer and inner joins\n",
        "\n",
        "1. Horizontal array stacking\n",
        "  * `np.hstack([array1, array2])`\n",
        "  * `np.concatenate([array1, array2], axis = 1)`\n",
        "2. Vertical array stacking\n",
        "  * `np.vstack([array1, array2])`\n",
        "  * `np.concatenate([array1, array2], axis = 0)`\n",
        "3. Outer joins include all indexes from the original tables without repetition (Set Union).\n",
        "4. Inner joins only include common indexes from different tables (Set Intersection).\n",
        "**Note:** We can specify which type of join we want to apply to our data using the `join` argument.\n",
        "\n",
        "**Note:** A `ValueError` is raised when the matrices have different sizes on the axis of concatenation!\n",
        "\n",
        "**Additional insights:**\n",
        "1. `np.array(Series_or_DataFrame)` converts a Series or a DataFrame into a NumPy array.\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB0ewkwoA-hj",
        "colab_type": "text"
      },
      "source": [
        "## Chapter 3: Merging Data\n",
        "\n",
        "### Section 1: Merging DataFrames\n",
        "\n",
        "`pd.merge(df1, df2)` works like an inner join.\n",
        "  * This function uses all common columns as bases to merge.\n",
        "  * We can select which columns will be bases for merging using the `on = []` argument.\n",
        "    * If the two columns have different names, we can use the `left_on = []` and `right_on = []` arguments.\n",
        "  * We can change the names of the column labels using the `suffixes = []` argument.\n",
        "\n",
        "### Section 2: Joining DataFrames\n",
        "\n",
        "Extending what we've learned from Section 1 of this Chapter:\n",
        "\n",
        "1. There are two more `join` types:\n",
        "  * Left join: all rows from the left DataFrame are kept.\n",
        "    * `how = \"left\"`\n",
        "  * Right join: all rows from the right DataFrame are kept.\n",
        "    * `how = \"right\"`\n",
        "2. The combination of the left and right join yields the outer join!\n",
        "3. There exists a `.join()` method in the pandas module.\n",
        "```\n",
        "# use .join()\n",
        "df1.join(df2, how = )\n",
        "```\n",
        "\n",
        "**Additional insights: Which should you use?**\n",
        "1. `.append` for simple stacking of Series data\n",
        "2. `pd.concat()` for stacking DataFrames with simple joins\n",
        "3. `df1.join(df2)` for joining\n",
        "4. `pd.merge(df1,df2)` for multiple joins on many columns\n",
        "\n",
        "<br>\n",
        "\n",
        "### Section 3: Ordered merges\n",
        "\n",
        "1. Sorting merges can be done by using the `.sort_values('col_name')`\n",
        "  * We can opt to use `pd.merge_ordered()` to drop the use `.sort_values('col_name')`.\n",
        "  * **Note:** `pd.merge()` does an INNER merge while `pd.merge_ordered()` does an OUTER merge by default.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5vRp_U9WBYx",
        "colab_type": "text"
      },
      "source": [
        "Tasks from this lesson (self-assessment)\n",
        "\n",
        "1. Preparing Data\n",
        "  * Reading multiple data files\n",
        "    * Did I read multiple data files using loops and/or the `glob` function?\n",
        "  * Reindexing DataFrames\n",
        "    * Did I manipulate DataFrame indices using the learned tools?\n",
        "  * Arithmetic with Series and DataFrames\n",
        "    * Did I do operations using methods like `.multiply()` or `.divide()`?\n",
        "\n",
        "2. Concatenating Data\n",
        "  * Appending and concatenating Series\n",
        "    * Did I append Series data?\n",
        "  * Appending and concatenating DataFrames\n",
        "    * Did I append/concatenate different DataFrames?\n",
        "  * Concatenation, keys, multi-indexes\n",
        "    * Did I concantenate DataFrames to create a multilevel DataFrame?\n",
        "\n",
        "3. Merging Data\n",
        "  * Merging DataFrames\n",
        "    * Did I merge DataFrames?\n",
        "  * Joining DataFrames\n",
        "    * Did I join DataFrames using one of the various joining methods?\n",
        "  * Ordered merges\n",
        "    * Did I do an ordered merge?"
      ]
    }
  ]
}